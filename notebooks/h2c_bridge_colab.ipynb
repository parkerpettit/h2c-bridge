{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# H2C Bridge - Colab Development Notebook"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "REPO_URL = \"https://github.com/YOUR_USERNAME/h2c-bridge.git\"  # UPDATE THIS\n",
                "\n",
                "import os\n",
                "if not os.path.exists(\"/content/h2c-bridge\"):\n",
                "    !git clone $REPO_URL /content/h2c-bridge\n",
                "    print(\"✅ Repository cloned\")\n",
                "else:\n",
                "    print(\"Repository already exists, pulling latest changes...\")\n",
                "    !cd /content/h2c-bridge && git pull\n",
                "\n",
                "%cd /content/h2c-bridge\n",
                "print(f\"Working directory: {os.getcwd()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install package in editable mode\n",
                "!pip install -q -e .\n",
                "!pip install -q -U bitsandbytes\n",
                "print(\"✅ Package installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enable autoreload for live code updates\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "print(\"✅ Autoreload enabled\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify WandB authentication\n",
                "import wandb\n",
                "\n",
                "# Set up once by running 'wandb login'\n",
                "try:\n",
                "    wandb.login()\n",
                "    print(\"✅ WandB authenticated\")\n",
                "    print(f\"   Logged in as: {wandb.api.viewer()['entity']}\")\n",
                "except Exception as e:\n",
                "    print(\"⚠️ WandB login failed. Run 'wandb login' in your local terminal.\")\n",
                "    print(f\"   Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize Components\n",
                "\n",
                "Set up models, data, and configuration. Edit `config.py` or `factory.py` and re-run this cell to test changes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from h2c_bridge.config import get_default_config\n",
                "from h2c_bridge.factory import H2CModelFactory\n",
                "from h2c_bridge.data.datamodule import H2CDataModule\n",
                "from h2c_bridge.utils import set_seed, clear_gpu\n",
                "\n",
                "# Set seed for reproducibility\n",
                "set_seed(42)\n",
                "\n",
                "# Get config and customize for development\n",
                "config = get_default_config()\n",
                "config.update({\n",
                "    \"SHARER_ID\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
                "    \"RECEIVER_ID\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
                "    \"MAX_SAMPLES\": 10_000,   # Smaller for faster iteration\n",
                "    \"BATCH_SIZE\": 4,\n",
                "    \"epochs\": 1,\n",
                "    \"eval_every\": 100,\n",
                "    \"verbose\": True,\n",
                "})\n",
                "\n",
                "print(\"Initializing Factory...\")\n",
                "factory = H2CModelFactory(config[\"SHARER_ID\"], config[\"RECEIVER_ID\"])\n",
                "tok_sharer, tok_receiver = factory.load_tokenizers()\n",
                "\n",
                "print(\"Initializing Data Module...\")\n",
                "dm = H2CDataModule(tok_sharer, tok_receiver, config)\n",
                "print(\"✅ Setup complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Quick Baseline Check (Optional)\n",
                "\n",
                "Verify the evaluation pipeline works before training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from h2c_bridge.training.engine import H2CEngine\n",
                "\n",
                "# Create engine\n",
                "engine = H2CEngine(factory, dm, config, lr=1e-4, eval_every=100)\n",
                "\n",
                "# Run quick baseline check\n",
                "print(\"Running baseline evaluation...\")\n",
                "baseline_results = engine.mmlu_evaluator.evaluate_baselines(engine.mmlu_loader)\n",
                "config[\"BASELINES\"] = baseline_results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training\n",
                "\n",
                "Train the bridge. Checkpoints automatically upload to WandB as artifacts with aliases:\n",
                "- `latest`: most recent checkpoint\n",
                "- `best`: highest accuracy\n",
                "- `final`: end of training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clear GPU and re-initialize for clean training run\n",
                "clear_gpu()\n",
                "engine = H2CEngine(factory, dm, config, lr=1e-4, eval_every=100)\n",
                "\n",
                "# Start training\n",
                "engine.run(epochs=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Resume from Checkpoint (Optional)\n",
                "\n",
                "Load a checkpoint from WandB artifacts to continue training or run inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Load the best checkpoint\n",
                "# Format: \"entity/project/artifact_name:alias\"\n",
                "# You can find this in your WandB UI under Artifacts\n",
                "\n",
                "# ARTIFACT_PATH = \"your-entity/nlp_project/bridge_Llama-3-1-8B-Instruct_TO_Qwen2-5-0-5B-Instruct_checkpoint:best\"\n",
                "# engine.load_checkpoint(ARTIFACT_PATH)\n",
                "# print(\"Checkpoint loaded! You can now continue training or run inference.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Debugging & Analysis\n",
                "\n",
                "Test specific components or run ad-hoc experiments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test a specific prompt\n",
                "prompt = \"Explain how a CPU works.\"\n",
                "engine.evaluator.generate_demo(prompt, max_new_tokens=100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check bridge gate statistics\n",
                "stats = engine.bridge.get_gate_stats()\n",
                "print(f\"Key Gate Avg: {stats['key_avg']:.4f}\")\n",
                "print(f\"Value Gate Avg: {stats['value_avg']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualizations (Optional)\n",
                "\n",
                "Generate publication-ready visualizations and upload to WandB."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to run full visualization suite\n",
                "# from h2c_bridge.visualization import run_all_visualizations\n",
                "# run_all_visualizations(engine, config, themes=(\"dark\", \"light\"))"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
